"use strict";(self.webpackChunkcontrast_docs=self.webpackChunkcontrast_docs||[]).push([[4081],{13118:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"howto/workload-deployment/GPU-configuration","title":"Configure GPU support","description":"Contrast supports running GPU workloads inside the confidential computing environment.","source":"@site/versioned_docs/version-1.11/howto/workload-deployment/GPU-configuration.md","sourceDirName":"howto/workload-deployment","slug":"/howto/workload-deployment/GPU-configuration","permalink":"/contrast/pr-preview/pr-1793/1.11/howto/workload-deployment/GPU-configuration","draft":false,"unlisted":false,"editUrl":"https://github.com/edgelesssys/contrast/edit/main/docs/versioned_docs/version-1.11/howto/workload-deployment/GPU-configuration.md","tags":[],"version":"1.11","frontMatter":{},"sidebar":"docs","previous":{"title":"Configure TLS","permalink":"/contrast/pr-preview/pr-1793/1.11/howto/workload-deployment/TLS-configuration"},"next":{"title":"Generate annotations & manifest","permalink":"/contrast/pr-preview/pr-1793/1.11/howto/workload-deployment/generate-annotations"}}');var r=o(74848),i=o(28453);const s={},a="Configure GPU support",l={},d=[{value:"Applicability",id:"applicability",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"How-to",id:"how-to",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"configure-gpu-support",children:"Configure GPU support"})}),"\n",(0,r.jsx)(n.p,{children:"Contrast supports running GPU workloads inside the confidential computing environment."}),"\n",(0,r.jsx)(n.h2,{id:"applicability",children:"Applicability"}),"\n",(0,r.jsx)(n.p,{children:"This step is optional and only necessary if your application includes a GPU workload (for example an AI model) that should run confidentially."}),"\n",(0,r.jsxs)(n.admonition,{type:"warning",children:[(0,r.jsxs)(n.p,{children:["Currently, confidential GPU workloads are supported ",(0,r.jsx)(n.strong,{children:"only"})," on bare-metal systems with AMD SEV-SNP.\nThey're ",(0,r.jsx)(n.strong,{children:"not"})," supported on AKS or on bare-metal systems using Intel TDX."]}),(0,r.jsx)(n.p,{children:"GPUs without Confidential Computing support can't be used with Contrast."}),(0,r.jsxs)(n.p,{children:["See the section on ",(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/cluster-setup/bare-metal#supported-gpu-hardware",children:"Supported GPU hardware"})," for more information."]})]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/cluster-setup/bare-metal",children:"Set up cluster"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/cluster-setup/bare-metal#preparing-a-cluster-for-gpu-usage",children:"Configure for GPU usage"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/install-cli",children:"Install CLI"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/workload-deployment/runtime-deployment",children:"Deploy the Contrast runtime"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/workload-deployment/add-coordinator",children:"Add Coordinator to resources"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/workload-deployment/deployment-file-preparation",children:"Prepare deployment files"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"how-to",children:"How-to"}),"\n",(0,r.jsxs)(n.p,{children:["If the cluster is ",(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/cluster-setup/bare-metal#preparing-a-cluster-for-gpu-usage",children:"configured for GPU usage"}),", Pods can use GPU devices if needed."]}),"\n",(0,r.jsxs)(n.p,{children:["To do so, a CDI annotation needs to be added, specifying to use the ",(0,r.jsx)(n.code,{children:"pgpu"})," (passthrough GPU) mode. The ",(0,r.jsx)(n.code,{children:"0"})," corresponds to the PCI device index."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["For nodes with a single GPU, this value is always ",(0,r.jsx)(n.code,{children:"0"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["For nodes with multiple GPUs, the value needs to correspond to the device's order as enumerated on the PCI bus. You can identify this order by inspecting the ",(0,r.jsx)(n.code,{children:"/var/run/cdi/nvidia.com-pgpu.yaml"})," file on the specific node."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This process ensures the correct GPU is allocated to the workload."}),"\n",(0,r.jsxs)(n.p,{children:["As the footprint of a GPU-enabled pod-VM is larger than one of a non-GPU one, the memory of the pod-VM can be adjusted by using the ",(0,r.jsx)(n.code,{children:"io.katacontainers.config.hypervisor.default_memory"})," annotation, which receives the memory the\nVM should receive in MiB. The example below sets it to 16 GB. A reasonable minimum for a GPU pod with a light workload is 8 GB."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'metadata:\n  # ...\n  annotations:\n    # ...\n    cdi.k8s.io/gpu: "nvidia.com/pgpu=0"\n    io.katacontainers.config.hypervisor.default_memory: "16384"\n'})}),"\n",(0,r.jsxs)(n.p,{children:["In addition, the container within the pod that requires GPU access must include a device request.\nThis request specifies the number of GPUs the container should use.\nThe identifiers for the GPUs, obtained during the ",(0,r.jsx)(n.a,{href:"/contrast/pr-preview/pr-1793/1.11/howto/cluster-setup/bare-metal#preparing-a-cluster-for-gpu-usage",children:"deployment of the NVIDIA GPU Operator"}),", must be included in the request.\nIn the provided example, the container is allocated a single NVIDIA H100 GPU."]}),"\n",(0,r.jsxs)(n.p,{children:["Finally, the environment variable ",(0,r.jsx)(n.code,{children:"NVIDIA_VISIBLE_DEVICES"})," must be set to ",(0,r.jsx)(n.code,{children:"all"})," to grant the container access to GPU utilities provided by the pod-VM. This includes essential tools like CUDA libraries, which are required for running GPU workloads."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'spec:\n  # ...\n  containers:\n    - # ...\n      resources:\n        limits:\n          "nvidia.com/GH100_H100_PCIE": 1\n      env:\n        # ...\n        - name: NVIDIA_VISIBLE_DEVICES\n          value: all\n'})}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"A pod configured to use GPU support may take a few minutes to come up, as the VM creation and boot procedure needs to do more work compared to a non-GPU pod."})})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>a});var t=o(96540);const r={},i=t.createContext(r);function s(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);