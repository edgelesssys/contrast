From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Charlotte Hartmann Paludo <git@charlotteharludo.com>
Date: Wed, 5 Nov 2025 13:01:25 +0100
Subject: [PATCH] runtime: assign GPU devices to multiple containers

Signed-off-by: Charlotte Hartmann Paludo <git@charlotteharludo.com>
---
 src/runtime/virtcontainers/container.go | 15 +++++++++++++++
 src/tools/genpolicy/src/pod.rs          | 11 +++++++++++
 src/tools/genpolicy/src/policy.rs       | 19 +++++++++++++++++++
 3 files changed, 45 insertions(+)

diff --git a/src/runtime/virtcontainers/container.go b/src/runtime/virtcontainers/container.go
index e1ae8d8ea1a419f1aa7c62423e38ebc3134d7f02..1424a06ffab017be32369f649d52a739568cc515 100644
--- a/src/runtime/virtcontainers/container.go
+++ b/src/runtime/virtcontainers/container.go
@@ -1126,6 +1126,14 @@ func (c *Container) annotateContainerWithVFIOMetadata(devices interface{}) error
 					return err
 				}
 			}
+
+			// If the NVIDIA_VISIBLE_DEVICES envvar exists and is set to "all" for the given container,
+			// we attach ALL Nvidia GPU devices to this container.
+			if slices.Contains(c.config.CustomSpec.Process.Env, "NVIDIA_VISIBLE_DEVICES=all") {
+				for _, sibling := range siblings {
+					c.createCDIAnnotation(sibling.Path, sibling.Index)
+				}
+			}
 		}
 
 		if devices, ok := devices.([]config.DeviceInfo); ok {
@@ -1140,6 +1148,13 @@ func (c *Container) annotateContainerWithVFIOMetadata(devices interface{}) error
 				}
 			}
 
+			// If the NVIDIA_VISIBLE_DEVICES envvar exists and is set to "all" for the given container,
+			// we attach ALL Nvidia GPU devices to this container.
+			if slices.Contains(c.config.CustomSpec.Process.Env, "NVIDIA_VISIBLE_DEVICES=all") {
+				for _, sibling := range siblings {
+					c.createCDIAnnotation(sibling.Path, sibling.Index)
+				}
+			}
 		}
 
 	}
diff --git a/src/tools/genpolicy/src/pod.rs b/src/tools/genpolicy/src/pod.rs
index 62fb2a4a7a070bb81ecc553d16a41711c84dd310..3d1e7b5bd95d18a84d4a336ddceec0d21ff8f0b3 100644
--- a/src/tools/genpolicy/src/pod.rs
+++ b/src/tools/genpolicy/src/pod.rs
@@ -1069,6 +1069,17 @@ impl Container {
             .and_then(|l| l.get("nvidia.com/pgpu"))
             .and_then(|v| v.parse::<usize>().ok())
     }
+
+    pub fn uses_nvidia_visible_devices(&self) -> bool {
+        for ev in self.env.as_ref().unwrap_or(&vec![]) {
+            if ev.name == "NVIDIA_VISIBLE_DEVICES"
+                && ev.value.as_ref().unwrap_or(&String::new()) == "all"
+            {
+                return true;
+            }
+        }
+        false
+    }
 }
 
 fn compress_default_capabilities(
diff --git a/src/tools/genpolicy/src/policy.rs b/src/tools/genpolicy/src/policy.rs
index f1f74e56bb25b83e339d06ee5123b5d4518b762b..8258844480aef0314c0e529f9e1399e8319a5e50 100644
--- a/src/tools/genpolicy/src/policy.rs
+++ b/src/tools/genpolicy/src/policy.rs
@@ -778,6 +778,25 @@ impl AgentPolicy {
             }
         }
 
+        // If the container is configured with NVIDIA_VISIBLE_DEVICES=all, it will also get the annotation.
+        if yaml_container.uses_nvidia_visible_devices() {
+                runtime_anno_patterns.insert(
+                    self.config
+                        .settings
+                        .device_annotations
+                        .vfio
+                        .key_regex
+                        .clone(),
+                    self.config
+                        .settings
+                        .device_annotations
+                        .vfio
+                        .nvidia_gpu_value_regex
+                        .clone(),
+                );
+        }
+
+
         for default_device in &c_settings.Linux.Devices {
             linux.Devices.push(default_device.clone())
         }
